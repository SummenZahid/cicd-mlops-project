#!/usr/bin/env python3
"""
Corrected API for CI/CD Failure Prediction
Handles raw input and transforms to model's expected format

This fixes the 422 error by accepting raw features and converting
to the one-hot encoded format the model expects.
"""

from fastapi import FastAPI, HTTPException
from pydantic import BaseModel, Field
from typing import Literal, Optional
import pickle
import json
import pandas as pd
import numpy as np
from datetime import datetime
import logging
import uvicorn

# Setup logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# Initialize FastAPI app
app = FastAPI(
    title="CI/CD Failure Prediction API",
    description="Predict whether a CI/CD pipeline run will fail",
    version="1.0.0"
)

# Global variables for model and metadata
model = None
model_metadata = None
expected_features = None


class PredictionInput(BaseModel):
    """Input schema for prediction - RAW FEATURES"""
    
    # Code metrics
    files_changed: int = Field(..., ge=0, description="Number of files changed")
    lines_added: int = Field(..., ge=0, description="Lines of code added")
    lines_deleted: int = Field(..., ge=0, description="Lines of code deleted")
    churn: int = Field(..., ge=0, description="Total code churn")
    
    # Test metrics
    test_count: int = Field(..., ge=0, description="Number of tests")
    test_failures: int = Field(..., ge=0, description="Number of test failures")
    test_fail_rate: float = Field(..., ge=0, le=1, description="Test failure rate")
    coverage_pct: float = Field(..., ge=0, le=100, description="Code coverage percentage")
    
    # Pipeline metrics
    pipeline_duration_s: float = Field(..., ge=0, description="Pipeline duration in seconds")
    jobs_total: int = Field(..., ge=0, description="Total number of jobs")
    artifact_size_mb: float = Field(..., ge=0, description="Artifact size in MB")
    
    # Historical metrics
    prev_7d_failure_rate: float = Field(..., ge=0, le=1, description="Failure rate in last 7 days")
    prev_30d_failure_rate: float = Field(..., ge=0, le=1, description="Failure rate in last 30 days")
    
    # Temporal features
    hour: int = Field(..., ge=0, le=23, description="Hour of day (0-23)")
    day_of_week: int = Field(..., ge=0, le=6, description="Day of week (0=Monday, 6=Sunday)")
    is_weekend: bool = Field(..., description="Whether it's a weekend")
    
    # Infrastructure
    runner_os: Literal["ubuntu", "windows", "macos"] = Field(..., description="Runner OS")
    cache_hit_rate: float = Field(..., ge=0, le=1, description="Cache hit rate")
    infra_alerts_count: int = Field(..., ge=0, description="Number of infrastructure alerts")

    class Config:
        json_schema_extra = {
            "example": {
                "files_changed": 15,
                "lines_added": 234,
                "lines_deleted": 89,
                "churn": 323,
                "test_count": 45,
                "test_failures": 2,
                "test_fail_rate": 0.044,
                "coverage_pct": 78.5,
                "pipeline_duration_s": 420.5,
                "jobs_total": 5,
                "artifact_size_mb": 125.3,
                "prev_7d_failure_rate": 0.15,
                "prev_30d_failure_rate": 0.22,
                "hour": 14,
                "day_of_week": 2,
                "is_weekend": False,
                "runner_os": "ubuntu",
                "cache_hit_rate": 0.85,
                "infra_alerts_count": 0
            }
        }


class PredictionOutput(BaseModel):
    """Output schema for prediction"""
    prediction: int = Field(..., description="Predicted class (0=success, 1=failure)")
    probability: float = Field(..., description="Probability of failure")
    model_used: str = Field(..., description="Model type used for prediction")
    prediction_time_ms: float = Field(..., description="Prediction time in milliseconds")


def transform_input_to_model_features(input_data: PredictionInput) -> pd.DataFrame:
    """
    Transform raw input to the format expected by the model
    
    This handles:
    - One-hot encoding of categorical variables
    - Feature engineering
    - Ensuring all expected features are present
    """
    
    # Convert input to dict
    data = input_data.model_dump()
    
    # Create DataFrame
    df = pd.DataFrame([data])
    
    # One-hot encode runner_os
    runner_os_dummies = pd.get_dummies(df['runner_os'], prefix='runner_os')
    df = pd.concat([df, runner_os_dummies], axis=1)
    df = df.drop('runner_os', axis=1)
    
    # Ensure all runner_os categories exist
    for os in ['ubuntu', 'windows', 'macos']:
        col_name = f'runner_os_{os}'
        if col_name not in df.columns:
            df[col_name] = 0
    
    # Ensure boolean is numeric
    df['is_weekend'] = df['is_weekend'].astype(int)
    
    # Ensure columns match model's expected features
    if expected_features is not None:
        # Add missing columns with 0
        for col in expected_features:
            if col not in df.columns:
                df[col] = 0
        
        # Reorder columns to match training
        df = df[expected_features]
    
    return df


@app.on_event("startup")
async def load_model():
    """Load model and metadata on startup"""
    global model, model_metadata, expected_features
    
    logger.info("="*80)
    logger.info("CI/CD FAILURE PREDICTION API - STARTING")
    logger.info(f"Python Version: {pd.__version__}")
    logger.info("="*80)
    
    try:
        # Load model
        model_path = "models/best_model_random_forest.pkl"
        logger.info(f"Loading model from {model_path}")
        
        with open(model_path, 'rb') as f:
            model = pickle.load(f)
        
        logger.info(f"Model loaded successfully: {type(model).__name__}")
        
        # Load metadata
        metadata_path = "models/best_model_metadata.json"
        try:
            with open(metadata_path, 'r') as f:
                model_metadata = json.load(f)
            
            # Get expected features from metadata
            if 'feature_names' in model_metadata:
                expected_features = model_metadata['feature_names']
                logger.info(f"Loaded metadata: {len(expected_features)} features")
            else:
                logger.warning("No feature_names in metadata, will use model's features")
                if hasattr(model, 'feature_names_in_'):
                    expected_features = list(model.feature_names_in_)
                    logger.info(f"Using model features: {len(expected_features)} features")
                else:
                    expected_features = None
                    logger.warning("Could not determine expected features")
                    
        except FileNotFoundError:
            logger.warning(f"Metadata file not found: {metadata_path}")
            if hasattr(model, 'feature_names_in_'):
                expected_features = list(model.feature_names_in_)
                logger.info(f"Using model features: {len(expected_features)} features")
        
    except Exception as e:
        logger.error(f"Failed to load model: {e}")
        raise


@app.get("/")
async def root():
    """Root endpoint"""
    return {
        "name": "CI/CD Failure Prediction API",
        "version": "1.0.0",
        "status": "running",
        "model_loaded": model is not None,
        "endpoints": {
            "health": "/health",
            "predict": "/predict (POST)",
            "model_info": "/model/info",
            "docs": "/docs"
        }
    }


@app.get("/health")
async def health_check():
    """Health check endpoint"""
    return {
        "status": "healthy",
        "model_loaded": model is not None,
        "timestamp": datetime.utcnow().isoformat()
    }


@app.get("/model/info")
async def model_info():
    """Get model information"""
    if model is None:
        raise HTTPException(status_code=503, detail="Model not loaded")
    
    info = {
        "model_type": type(model).__name__,
        "status": "ready",
        "expected_features": len(expected_features) if expected_features else "unknown"
    }
    
    # Add metadata if available
    if model_metadata:
        info.update({
            "metrics": model_metadata.get("metrics", {}),
            "trained_at": model_metadata.get("trained_at", "unknown"),
            "version": model_metadata.get("version", "1.0")
        })
    
    return info


@app.post("/predict", response_model=PredictionOutput)
async def predict(input_data: PredictionInput):
    """
    Make a prediction for a CI/CD pipeline run
    
    Accepts raw features and transforms them to model's expected format
    """
    if model is None:
        raise HTTPException(status_code=503, detail="Model not loaded")
    
    try:
        import time
        start_time = time.time()
        
        # Transform input to model features
        logger.info("Transforming input features...")
        X = transform_input_to_model_features(input_data)
        
        logger.info(f"Features shape: {X.shape}")
        logger.info(f"Features: {list(X.columns)[:10]}... (showing first 10)")
        
        # Make prediction
        prediction = int(model.predict(X)[0])
        probability = float(model.predict_proba(X)[0][1])  # Probability of failure
        
        prediction_time = (time.time() - start_time) * 1000  # Convert to ms
        
        logger.info(f"Prediction: {prediction}, Probability: {probability:.3f}, Time: {prediction_time:.2f}ms")
        
        return PredictionOutput(
            prediction=prediction,
            probability=probability,
            model_used=type(model).__name__,
            prediction_time_ms=round(prediction_time, 2)
        )
        
    except Exception as e:
        logger.error(f"Prediction error: {e}")
        raise HTTPException(status_code=500, detail=f"Prediction failed: {str(e)}")


if __name__ == "__main__":
    logger.info("Starting FastAPI server...")
    logger.info(f"Python version: {pd.__version__}")
    
    uvicorn.run(
        app,
        host="0.0.0.0",
        port=8000,
        log_level="info"
    )